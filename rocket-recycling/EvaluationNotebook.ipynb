{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cc860e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from rocket import Rocket\n",
    "\n",
    "task = 'hover'  # 'hover' or 'landing'\n",
    "max_episode = 5\n",
    "max_steps = 800\n",
    "\n",
    "\n",
    "import random\n",
    "import torch\n",
    "from collections import deque\n",
    "\n",
    "alpha = 0.001\n",
    "gamma = 0.99\n",
    "lmbda         = 0.99\n",
    "eps_clip      = 0.1\n",
    "K_epoch       = 4\n",
    "\n",
    "env = Rocket(task=task, max_steps=max_steps)\n",
    "\n",
    "\n",
    "class VNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fcV1 = torch.nn.Linear(8, 256)\n",
    "        self.fcV2 = torch.nn.Linear(256, 256)\n",
    "        #add an additional layer\n",
    "#         self.fcV3 = torch.nn.Linear(256, 512)\n",
    "        self.fcV3 = torch.nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcV1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fcV2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fcV3(x)\n",
    "#         x = torch.nn.functional.relu(x)\n",
    "#         x = self.fcV4(x)\n",
    "        return x\n",
    "    \n",
    "class PolicyNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fcA1 = torch.nn.Linear(8, 256)\n",
    "        self.fcA2 = torch.nn.Linear(256, 256)\n",
    "        #add one layer\n",
    "#         self.fcA3 = torch.nn.Linear(256, 512)\n",
    "        self.fcA3_thrust = torch.nn.Linear(256,3)\n",
    "        self.fcA3 = torch.nn.Linear(256, 9)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fcA1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fcA2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fcA3(x)  \n",
    "#         x = torch.nn.functional.relu(x)\n",
    "#         x = self.fcA4(x)  \n",
    "        x = torch.nn.functional.softmax(x, dim=-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bee379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/joonpark/Desktop/KAIST_Y4S2/강화학습개론/FinalProject/rocket-recycling'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5db2b995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolicyNetwork(\n",
       "  (fcA1): Linear(in_features=8, out_features=256, bias=True)\n",
       "  (fcA2): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fcA3_thrust): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (fcA3): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load saved networks for testing:\n",
    "base_path = os.getcwd() + '/checkpoints'\n",
    "date = '2023-05-20'\n",
    "\n",
    "pi_test = PolicyNetwork()\n",
    "# V_test = VNetwork()\n",
    "\n",
    "# v_path = base_path + '/VNetwork/' + date + '_best_v_state.pt'\n",
    "pi_path = base_path + '/PolicyNetwork/' + date + '_best_pi_state.pt'\n",
    "# V_test.load_state_dict(torch.load(v_path))\n",
    "pi_test.load_state_dict(torch.load(pi_path))\n",
    "\n",
    "# pi_test.cuda()\n",
    "pi_test.eval()\n",
    "\n",
    "# V_test.cuda()\n",
    "# V_test.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a75b978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PolicyNetwork(\n",
      "  (fcA1): Linear(in_features=8, out_features=256, bias=True)\n",
      "  (fcA2): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (fcA3): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fcA4): Linear(in_features=512, out_features=9, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(pi_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9819f4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rewards = 69.7398674038349\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for episode in range(max_episode):\n",
    "    state = env.reset()\n",
    "    \n",
    "    score = 0\n",
    "    rewards= []\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        probs_target = pi_test(torch.FloatTensor(state))\n",
    "        action = torch.multinomial(probs_target, 1).item()\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        env.render()\n",
    "        \n",
    "        score += reward\n",
    "        \n",
    "        if done or step == max_steps-1:\n",
    "            rewards.append(score)\n",
    "            cv2.destroyAllWindows()\n",
    "            break\n",
    "\n",
    "average = np.mean(np.array(rewards))\n",
    "print(f'average rewards = {average}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b5fb76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
